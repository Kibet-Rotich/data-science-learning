{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1927af5d",
   "metadata": {},
   "source": [
    "# ðŸ§  MNIST Digit Classification\n",
    "\n",
    "In this notebook, weâ€™ll build, train, and evaluate two models for classifying handwritten digits from the **MNIST dataset**:\n",
    "\n",
    "1. A simple **Artificial Neural Network (ANN)**.\n",
    "2. A **Convolutional Neural Network (CNN)** for improved performance on image data.\n",
    "\n",
    "Weâ€™ll also try out real handwritten digit images to see how well our models generalize beyond the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399308b1",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Step 1: Load the MNIST Dataset\n",
    "\n",
    "Weâ€™ll use TensorFlowâ€™s built-in dataset loader. The MNIST dataset contains **60,000 training** and **10,000 test** grayscale images of handwritten digits (0â€“9), each of size 28Ã—28 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a66d70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(f\"Training samples: {x_train.shape[0]}, Test samples: {x_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec32bfe",
   "metadata": {},
   "source": [
    "## ðŸ”§ Step 2: Preprocess the Data\n",
    "\n",
    "- Normalize pixel values from 0â€“255 to 0â€“1 for better numerical stability.\n",
    "- Flatten 28Ã—28 images into 784-dimensional vectors for the ANN.\n",
    "- One-hot encode the labels (e.g., digit 3 â†’ `[0,0,0,1,0,0,0,0,0,0]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b0f794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "# Normalize pixel values\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Flatten images (28x28 â†’ 784)\n",
    "x_train = x_train.reshape(-1, 784)\n",
    "x_test = x_test.reshape(-1, 784)\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e128bd35",
   "metadata": {},
   "source": [
    "## ðŸ—ï¸ Step 3: Build the Neural Network (ANN)\n",
    "\n",
    "Weâ€™ll start with a simple feedforward neural network with:\n",
    "- 2 hidden layers (128 and 64 neurons, ReLU activation)\n",
    "- Output layer (10 neurons, softmax for class probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33f3d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(784,)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd9b597",
   "metadata": {},
   "source": [
    "## ðŸ§® Step 4: Train the Model\n",
    "\n",
    "Weâ€™ll train for 10 epochs and observe both training and validation accuracy to check for overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc6f683",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57acca9e",
   "metadata": {},
   "source": [
    "## ðŸ“Š Step 5: Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec14f7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"\\nâœ… Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ec4941",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Step 6: Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea40390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3613bb4",
   "metadata": {},
   "source": [
    "## ðŸ–¼ï¸ Step 7: Test on Custom Handwritten Digits\n",
    "\n",
    "You can upload images named `0.jpg`, `1.jpg`, â€¦ `9.jpg` and test how the model performs on your own handwriting.\n",
    "\n",
    "We'll preprocess each image just like MNIST: grayscale â†’ invert â†’ normalize â†’ flatten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03903bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "correct, total = 0, 0\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for idx, file_name in enumerate(sorted(glob.glob('*.jpg'))):\n",
    "    img = Image.open(file_name).convert('L').resize((28, 28))\n",
    "    img_array = np.array(img)\n",
    "    if img_array.mean() > 127:\n",
    "        img_array = 255 - img_array\n",
    "    img_array = img_array / 255.0\n",
    "    img_array_flat = img_array.reshape(1, 784)\n",
    "\n",
    "    prediction = model.predict(img_array_flat, verbose=0)\n",
    "    pred_digit = np.argmax(prediction)\n",
    "    actual_digit = int(os.path.splitext(file_name)[0])\n",
    "\n",
    "    if pred_digit == actual_digit:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "\n",
    "    plt.subplot(2, 5, idx + 1)\n",
    "    plt.imshow(img_array, cmap='gray')\n",
    "    plt.title(f'Pred: {pred_digit}\\nAct: {actual_digit}')\n",
    "    plt.axis('off')\n",
    "\n",
    "acc = (correct / total * 100) if total else 0\n",
    "print(f\"Custom image accuracy: {acc:.2f}%\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d123629",
   "metadata": {},
   "source": [
    "## ðŸ§± Step 8: Build a CNN for Better Image Understanding\n",
    "\n",
    "A **Convolutional Neural Network (CNN)** leverages spatial structure in images, leading to significantly higher accuracy.\n",
    "\n",
    "**Key improvements over ANN:**\n",
    "- Local connectivity (focuses on small image patches)\n",
    "- Weight sharing (same filter detects features anywhere)\n",
    "- Translation invariance (digit position doesnâ€™t matter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb74b47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "# Reload MNIST (for 2D image input)\n",
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape((-1, 28, 28, 1)).astype('float32') / 255.0\n",
    "x_test = x_test.reshape((-1, 28, 28, 1)).astype('float32') / 255.0\n",
    "\n",
    "# Build CNN\n",
    "cnn = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbf0f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train CNN\n",
    "cnn_history = cnn.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a02bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate CNN\n",
    "test_loss, test_acc = cnn.evaluate(x_test, y_test)\n",
    "print(f\"\\nâœ… CNN Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022565c3",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Step 9: Save Models for Future Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f28709",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mnist_ann_model.h5')\n",
    "cnn.save('mnist_cnn_model.h5')\n",
    "print(\"Models saved: mnist_ann_model.h5 and mnist_cnn_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f91f7b",
   "metadata": {},
   "source": [
    "## ðŸ§© Step 10: Summary\n",
    "\n",
    "- ANN achieved decent performance but struggles with generalizing to non-MNIST digits.\n",
    "- CNN captured spatial patterns better and achieved much higher accuracy.\n",
    "- Real-world performance depends heavily on preprocessing quality (contrast, alignment, noise).\n",
    "\n",
    "**Next Steps:**\n",
    "- Add dropout or batch normalization.\n",
    "- Train longer with data augmentation.\n",
    "- Try digit segmentation for multiple-digit images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
